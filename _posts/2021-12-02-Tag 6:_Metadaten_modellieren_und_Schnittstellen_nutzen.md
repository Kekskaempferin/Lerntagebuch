---
titel: "Tag 6: Metadaten modellieren und Schnittstellen nutzen"
date: 2021-12-02
---

Inzwischen haben wir also im Kurs in drei verschiedenen Systemen Metadaten mit unterschiedlichen Datenformate generiert. Koha haben wir genutzt für das Erfassen bibliothekarischer Metadaten mit MARC21-XML. In AchivesSpace haben wir Metadaten für ein Archive im Format EAD erfasst. DSpace als Beispiel für Online-Repositorien beinhaltet Metadaten im Format Dublin Core. In der letzten Sitzung haben wir die Metadaten aus DSpace bereits über die OAI-PMH-Schnittstelle abgerufen. Dies wollen wir nun auch für ArchivesSpace und Koha versuchen. Die Metadaten werden anschliessend mit der Software marcEdit vereinheitlicht. 

**Metadaten harvesten**<br>
Im Bibliotheks- und Archivbereich werden viele verschiedene  Übertragungsprotokolle verwendet. Am häufigsten verbreitet sind Z29.50, SRU und OAI-PMH. Während Z39.50 zwar doch schon älter ist, wird es dennoch immer noch vielerorts angeboten. Meist wird es aber durch das modernere SRU ergänzt. Diese beiden Protokolle eigenen sich für gezielte Suchanfragen mit vielen Parameter. Dem gegenüber steht OAI-PMH als Protokoll für grosse Datenmengen und regelmässige Aktualisierungen. Sowohl SRU wie auch OAI-PMH benötigen eigentlich keine zusätzliche Software, weil Anfragen direkt als URL zusammengestellt werden können. 
Für das Abgreifen unserer Metadaten in ArchivesSpace und Koha nutzen wir OAI-PMH. Dazu nutzen wir das Discovery System VuFind, welches wir zunächst auf unserem Rechner installieren müssen. Damit das auch funktioniert, müssen die OAI-PMH-Endpoints in Koha und AchivesSpace verfügbar sein. An dieser Stelle erschliesst sich mir nicht ganz, weshalb wir extra eine Software herunterladen, um die Daten zu ernten, wenn doch OAI-PMH anscheinend keine Extra-Software braucht? Gilt dies eventuell nur für Abfragen, nicht aber wenn die Daten gespeichert werden sollen?
In meinem Fall hat das Harvesten mit VuFind ohne Probleme funktioniert. Die Aufnahme der Vorlesung zum Mitmachen sowie die Befehle für das Terminal zum Kopieren haben den Prozess stark vereinfacht. Ich musste daher nicht auf die Beispieldaten zurückgreifen. 
<br> <br>
**Konvertierung der Metadaten** <br>
Der Prozess der Konvertierung von einem Metadatenstandard zum anderen wird Crosswalk genannt. Er beinhaltet regeln, wie Elemente und Werte aus dem alten Standard im neuen zugeordnet werden sollen. Dieser Prozess ist idealerweise Verlustfrei. In der Praxis ist aber meist keine 1:1 Zuordnung möglich. Ich würde vermuten, dass konvertierte Daten generell eher allgemeiner sind als in ihrem ursprünglichen Format. Beispielsweise bei der Umwandlung von Dublin Core zu MARC21. MARC21 ist mit deinen diversen Unterfelder und Indikatoren viel detaillierter als Dublin Core. Der Konverter wird die Daten, welche in DC gespeichert wurden, nicht detaillierter verarbeiten können, als DC das getan hat. Weshalb sie auch in MARC21 in der allgemeinsten Form gewählt werden muss. Zusätzlich existieren in DC eventuell Felder, welche MARC21 so gar nicht kennt und eventuell sogar verloren gehen. 

Zur Konvertierung unserer Metadaten verwenden wir das Tool MarcEdit7, welches für den Crosswalk die Programmiersprache XSLT verwendet. XSLT ist eine Programmiersprache spezifisch zur Transformation von XML-Dokumenten. Auch MarcEdit7 muss zuerst installiert und konfiguriert werden. Auch hier waren die Aufzeichnung und die Befehle im gemeinsamen Dokument wieder sehr hilfreich. Bei der Konfigurierung hatte ich zweitweilen etwas Schwierigkeiten, da das Programm beim ersten Start nicht gleich reagiert hat wie in der Demonstration. Das hat sich dann aber auch wieder gelöst. Bei der eigentlichen Konvertierung der Daten mit dem XSLT Crosswalk bin ich unsicher, ob die Daten, die ich habe, korrekt gespeichert wurden. Ich hatte ein seltsames Problem, dass Dateien plötzlich verschwunden sind nach der Konvertierung. Ich glaube aber, dass es schliesslich funktioniert hat. Ich werde es vermutlich später merken. Zur Not nutze ich dann halt die Beispieldaten. 
